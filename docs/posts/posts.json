[
  {
    "path": "posts/2022-05-09-new-paper-on-walking-activity-recognition/",
    "title": "New paper on walking activity recognition",
    "description": "Check out our newly published research which presents a unified framework to \nperform walking activity recognition from rotation time series collected by a \nwearable sensor in a free-living environment.",
    "author": [
      {
        "name": "Aymeric Stamm",
        "url": "https://astamm.github.io"
      }
    ],
    "date": "2022-05-09",
    "categories": [
      "research",
      "rotation data"
    ],
    "contents": "\n\n\n\nSolutions to assess walking deficiencies are widespread and largely\nused in healthcare. Wearable sensors are particularly appealing, as they\noffer the possibility to monitor gait in everyday life, outside a\nfacility in which the context of evaluation biases the measure. While\nsome wearable sensors are powerful enough to integrate complex walking\nactivity recognition models, non-invasive lightweight sensors do not\nalways have the computing or memory capacity to run them. In this paper,\nwe propose a walking activity recognition model that offers a viable\nsolution to this problem for any wearable sensors that measure\nrotational motion of body parts. Specifically, the model was trained and\ntuned using data collected by a motion sensor in the form of a unit\nquaternion time series recording the hip rotation over time. This time\nseries was then transformed into a real-valued time series of geodesic\ndistances between consecutive quaternions. Moving average and moving\nstandard deviation versions of this time series were fed to standard\nmachine learning classification algorithms. To compare the different\nmodels, we used metrics to assess classification performance (precision\nand accuracy) while maintaining the detection prevalence at the level of\nthe prevalence of walking activities in the data, as well as metrics to\nassess change point detection capability and computation time. Our\nresults suggest that the walking activity recognition model with a\ndecision tree classifier yields the best compromise in terms of\nprecision and computation time. The sensor that was used had purposely\nlow computing and memory capacity so that reported performances can be\nthought of as the lower bounds of what can be achieved. Walking activity\nrecognition is performed online, i.e., on-the-fly, which further extends\nthe range of applicability of our model to sensors with very low memory\ncapacity.\nFind out more by reading our paper (Brard et al. 2022) which can be found at\nhttps://doi.org/10.3390/s22093555.\n\n\n\nBrard, Raphaël, Lise Bellanger, Laurent Chevreuil, Fanny Doistau, Pierre\nDrouin, and Aymeric Stamm. 2022. “A Novel Walking Activity\nRecognition Model for Rotation Time Series Collected by a Wearable\nSensor in a Free-Living Environment.” Sensors 1. https://doi.org/10.3390/s22093555.\n\n\n\n\n",
    "preview": "posts/2022-05-09-new-paper-on-walking-activity-recognition/new-paper-on-walking-activity-recognition_files/figure-html5/logo-1.png",
    "last_modified": "2022-05-09T16:17:45+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2022-05-09-riot-001/",
    "title": "riot 0.0.1",
    "description": "An R interface for Popular Tractography File Formats",
    "author": [
      {
        "name": "Aymeric Stamm",
        "url": "https://astamm.github.io"
      }
    ],
    "date": "2022-05-09",
    "categories": [
      "software",
      "connectomics"
    ],
    "contents": "\n\n\n\nOverview\nThe riot (R\nInput/Output for Tractography) package provides an R interface to import\ntractography data in R. Currently supported formats for importing are\nnative VTK .vtk and\n.vtp files as well as MRtrix\n.tck/.tsf files and TrackVis\n.trk files.\nInstallation\nYou can install the package directly from CRAN:\ninstall.packages(\"riot\")\nor you can choose to install the development version from GitHub:\n# install.packages(\"remotes\")\nremotes::install_github(\"astamm/riot\")\nThe package has its own webpage: https://astamm.github.io/riot/.\n\n\n\n",
    "preview": "posts/2022-05-09-riot-001/riot-001_files/figure-html5/logo-1.png",
    "last_modified": "2022-05-09T16:17:45+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2022-04-27-new-paper-on-domain-selection-for-functional-data/",
    "title": "New paper on domain selection for functional data",
    "description": "Check out our newly published research which presents a unified framework to \nperform domain selection for functional data with familywise error rate control.",
    "author": [
      {
        "name": "Aymeric Stamm",
        "url": "https://astamm.github.io"
      }
    ],
    "date": "2022-04-27",
    "categories": [
      "research",
      "functional data"
    ],
    "contents": "\n\n\n\nFunctional data are smooth, often continuous, random curves, which\ncan be seen as an extreme case of multivariate data with infinite\ndimensionality. Just as component-wise inference for multivariate data\nnaturally performs feature selection, subset-wise inference for\nfunctional data performs domain selection. In this paper, we present a\nunified testing framework for domain selection on populations of\nfunctional data. In detail, \\(p\\)-values of hypothesis tests performed on\npoint-wise evaluations of functional data are suitably adjusted for\nproviding control of the family-wise error rate (FWER) over a family of\nsubsets of the domain. We show that several state-of-the-art domain\nselection methods fit within this framework and differ from each other\nby the choice of the family over which the control of the FWER is\nprovided. In the existing literature, these families are always defined\na priori. In this work, we also propose a novel approach, coined\nthreshold-wise testing, in which the family of subsets is instead built\nin a data-driven fashion. The method seamlessly generalizes to\nmultidimensional domains in contrast to methods based on a priori\ndefined families. We provide theoretical results with respect to\nconsistency and control of the FWER for the methods within the unified\nframework. We illustrate the performance of the methods within the\nunified framework on simulated and real data examples and compare their\nperformance with other existing methods.\nFind out more by reading our paper (Abramowicz et al. 2022) which can be\nfound at https://onlinelibrary.wiley.com/doi/10.1111/biom.13669.\n\n\n\nAbramowicz, Konrad, Alessia Pini, Lina Schelin, Sara Sjöstedt de Luna,\nAymeric Stamm, and Simone Vantini. 2022. “Domain Selection and\nFamily-Wise Error Rate for Functional Data: A Unified Framework.”\nBiometrics. https://doi.org/10.1111/biom.13669.\n\n\n\n\n",
    "preview": "posts/2022-04-27-new-paper-on-domain-selection-for-functional-data/new-paper-on-domain-selection-for-functional-data_files/figure-html5/logo-1.png",
    "last_modified": "2022-05-09T16:17:45+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2022-02-01-roahd-143/",
    "title": "roahd 1.4.3",
    "description": "An R package for the RObust Analysis of High-dimensional Data",
    "author": [
      {
        "name": "Aymeric Stamm",
        "url": "https://astamm.github.io"
      }
    ],
    "date": "2022-01-31",
    "categories": [
      "software",
      "functional data"
    ],
    "contents": "\n\n\n\nOverview\nThe roahd (Robust Analysis of High-dimensional Data) package (Ieva et al. 2019) allows to use a set of statistical tools for the exploration and robustification of univariate and multivariate functional data sets through the use of depth-based statistical methods.\nIn the implementation of functions, special attention was put to their efficiency, so that they can be profitably used also for the analysis of high-dimensional datasets.\nFor a full-featured description of the package, please take a look at the roahd vignette.\nNew feature\nWe added tools for manipulating and visualizing depthgrams (Aleman-Gomez et al. 2021). This mathematical constructs aim at facilitating the visualization of outliers in high dimensional functional data sets. The depthgram() function computes a number of depthgrams from the functional data set. An S3 specialized method for plot() makes it possible to visualize the depthgrams and proceed with a visual inspection at outliers.\n\n\n\nAleman-Gomez, Yasser, Ana Arribas-Gil, Manuel Desco, Antonio Elias-Fernandez, and Juan Romo. 2021. “Visualizing Outliers in High Dimensional Functional Data for Task fMRI Data Exploration.” arXiv Preprint arXiv:2103.08874.\n\n\nIeva, Francesca, Anna Maria Paganoni, Juan Romo, and Nicholas Tarabelloni. 2019. “roahd Package: Robust Analysis of High Dimensional Data.” The R Journal 11 (2): 291–307. https://doi.org/10.32614/RJ-2019-032.\n\n\n\n\n",
    "preview": "posts/2022-02-01-roahd-143/roahd-143_files/figure-html5/logo-1.png",
    "last_modified": "2022-02-01T14:33:42+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2022-02-01-nloptr-200/",
    "title": "nloptr 2.0.0",
    "description": "A new version of the nloptr package has been released! The NLopt library has switched to CMake as build system. I am replacing Jelmer Ypma as maintainer of the package.",
    "author": [
      {
        "name": "Aymeric Stamm",
        "url": "https://astamm.github.io"
      }
    ],
    "date": "2022-01-28",
    "categories": [
      "software",
      "optimization"
    ],
    "contents": "\n\n\n\n\nA new version of the nloptr package has been released! The NLopt library has switched to CMake as build system. I am replacing Jelmer Ypma as maintainer of the package.\n\nnlopt\nThe NLopt library (Johnson 2021) is a free/open-source library for nonlinear optimization, providing a common interface for a number of different free optimization routines available online as well as original implementations of various other algorithms.\nStarting from v2.5.0, NLopt has switched to cmake as build system, making the latest versions incompatible with the way nloptr used to interface the library.\nnloptr\nAs of v2.0.0, we now provide an R interface to nlopt >= 2.7.0. This is achieved in different ways depending on the operating system you are using.\nWindows\nThere is no dependency required for Windows users.\nIf you are running on R <= 4.1.x, installation of nloptr will rely on a valid internet connexion to download the nlopt 2.7.1 headers and static library from rwinlib and use it.\nIf you are running on R >= 4.2.x, installation of nloptr will directly link with nlopt 2.7.1 from the Rtools42 toolchain.\nLinux and macOS\nOn Unix-like systems, installation of nloptr will go through the following steps:\nIs pkg-config available on your PATH?\nNO: compile nlopt 2.7.1 from included sources using cmake >= 3.15.0.\nYES: can pkg-config detect a system build of nlopt >= 2.7.0?\nNO: compile nlopt 2.7.1 from included sources using cmake >= 3.15.0.\nYES: install nloptr using the detected system build of nlopt.\n\nHence, cmake >= 3.15.0 can become a system requirement for installing nloptr on your machine if you are running on a Unix-like system without pkg-config or without a system build of nlopt >= 2.7.0.\n\n\n\nJohnson, Steven G. 2021. The NLopt Nonlinear-Optimization Package (version 2.7.1). https://nlopt.readthedocs.io/en/latest/.\n\n\n\n\n",
    "preview": "posts/2022-02-01-nloptr-200/nloptr-200_files/figure-html5/logo-1.png",
    "last_modified": "2022-02-01T13:53:09+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2022-02-01-nevada-010/",
    "title": "nevada 0.1.0",
    "description": "A new package for making inference on populations of graphs.",
    "author": [
      {
        "name": "Aymeric Stamm",
        "url": "https://astamm.github.io"
      }
    ],
    "date": "2021-09-25",
    "categories": [
      "software",
      "network-valued data"
    ],
    "contents": "\n\n\n\nSummary\nThe package nevada (NEtwork-VAlued Data Analysis) is an R package for the statistical analysis of network-valued data. In this setting, a sample is made of statistical units that are networks themselves. The package provides a set of matrix representations for networks so that network-valued data can be transformed into matrix-valued data. Subsequently, a number of distances between matrices is provided as well to quantify how far two networks are from each other and several test statistics are proposed for testing equality in distribution between samples of networks using exact permutation testing procedures. The permutation scheme is carried out by the flipr package which also provides a number of test statistics based on inter-point distances that play nicely with network-valued data. The implementation is largely made in C++ and the matrix of inter- and intra-sample distances is pre-computed, which alleviates the computational burden often associated with permutation tests.\nPipeline\nNetwork-valued data are data in which the statistical unit is a network itself. This is the data with which we can make inference on populations of networks from samples of networks. The nevada package proposes a specific nvd class to handle network-valued data. Inference from such samples is made possible though a 4-step procedure:\nChoose a suitable representation of your samples of networks.\nChoose a suitable distance to embed your representation into a nice metric space.\nChoose one or more test statistics to define your alternative hypothesis.\nCompute an empirical permutation-based approximation of the null distribution.\nThe package focuses for now on the two-sample testing problem and assumes that all networks from both samples share the same node structure.\nThere are two types of questions that one can ask:\nIs there a difference between the distributions that generated the two observed samples?\nCan we localize the differences between the distributions on the node structure?\nThe nevada package offers a dedicated function for answering each of these two questions:\ntest2_global(); for more details, please see Lovato et al. (2020),\ntest2_local(); for more details, please see Lovato et al. (2021).\n\n\n\nLovato, Ilenia, Alessia Pini, Aymeric Stamm, Maxime Taquet, and Simone Vantini. 2021. “Multiscale Null Hypothesis Testing for Network-Valued Data: Analysis of Brain Networks of Patients with Autism.” Journal of the Royal Statistical Society: Series C (Applied Statistics), January. https://doi.org/10.1111/rssc.12463.\n\n\nLovato, Ilenia, Alessia Pini, Aymeric Stamm, and Simone Vantini. 2020. “Model-Free Two-Sample Test for Network-Valued Data.” Computational Statistics & Data Analysis 144 (April): 106896. https://doi.org/10.1016/j.csda.2019.106896.\n\n\n\n\n",
    "preview": "posts/2022-02-01-nevada-010/nevada-010_files/figure-html5/logo-1.png",
    "last_modified": "2022-02-01T14:16:46+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-04-08-ms-csi-mainstream1/",
    "title": "Mainstream Report #1",
    "description": "The first mainstream report for the MS-CSI project is now available online!",
    "author": [
      {
        "name": "Aymeric Stamm",
        "url": "https://astamm.github.io"
      }
    ],
    "date": "2021-04-08",
    "categories": [
      "research",
      "ms-csi"
    ],
    "contents": "\n\n\n\nThe MS-CSI project is funded by the Association pour la Recherche en Sclérose En Plaques (ARSEP) through a number of French donors. It is important for the donors to have mainstream material that they can read to understand what scientific discoveries we were able to make thanks to their donations. A first mainstream report for general audience is now available here. It is intended to be read by French native speakers and is thus written in French. In this troubled period of global pandemic, the MS-CSI project has been delayed and we expect it to start next September 2021. However, in the meantime, a number of milestones have been achieved around our eGait solution that we wanted to share with our generous donors and, more generally, to the general audience who care about MS.\n\n\n\n",
    "preview": "posts/2021-04-08-ms-csi-mainstream1/ms-csi-mainstream1_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2022-02-01T10:14:04+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-04-06-flipr-021/",
    "title": "flipr 0.2.1",
    "description": "A new version of the flipr package has been released! Check it out if you are looking for a consistent, robust and easy way of doing permutation inference.",
    "author": [
      {
        "name": "Aymeric Stamm",
        "url": "https://astamm.github.io"
      }
    ],
    "date": "2021-04-06",
    "categories": [
      "software",
      "permutation inference"
    ],
    "contents": "\n\n\n\nThe permutation framework is particularly well suited for inferential purposes as it allows one to do point estimation, confidence regions and hypothesis tests. The flipr package makes it easy and fun to perform all these inferential tasks within the permutation paradigm.\nThe central object is the so-called \\(p\\)-value function. The \\(p\\)-value function for a set of parameters \\(\\Theta\\) is a curve that represents the variation of the \\(p\\)-value of an hypothesis test in which the null hypothesis is \\(\\Theta = \\Theta_0\\) as a function of \\(\\Theta_0\\) (Martin 2017; Fraser 2019; Infanger and Schmidt-Trucksäss 2019).\nObserve that, the non-parametric combination method available in the permutation framework (Pesarin and Salmaso 2010) allows you to infer multiple parameters at once. This means that you can natively compute a single confidence region for multiple parameters that controls the family-wise error rate by construction (think of a confidence region for both the mean and the variance for instance).\nVersion 0.2.1 of the flipr package released on CRAN features \\(4\\) main functions:\nYou can compute \\(p\\)-value function when inferring multiple parameters at once via two_sample_pf();\nYou can compute a single point estimate for a single parameter of interest via two_sample_pe();\nYou can compute a confidence interval for a single parameter of interest via two_sample_ci();\nYou can automatically draw the \\(p\\)-value function for a single parameter of interest via two_sample_viz().\nThis version also implements a number of small changes and bug fixes, the full list of which is available here.\nFinally, a number of articles can be found on the dedicated website for flipr: https://astamm.github.io/flipr/. They explain in details how the permutation framework can be used for statistical inference and how flipr offers easy tools for making that happen seamlessly.\n\n\n\nFraser, D. A. S. 2019. “The p-Value Function and Statistical Inference.” The American Statistician 73 (sup1): 135–47. https://doi.org/10.1080/00031305.2018.1556735.\n\n\nInfanger, Denis, and Arno Schmidt-Trucksäss. 2019. “P Value Functions: An Underused Method to Present Research Results and to Promote Quantitative Reasoning.” Statistics in Medicine 38 (21): 4189–97. https://doi.org/10.1002/sim.8293.\n\n\nMartin, Ryan. 2017. “A Statistical Inference Course Based on p-Values.” The American Statistician 71 (2): 128–36. https://doi.org/10.1080/00031305.2016.1208629.\n\n\nPesarin, Fortunato, and Luigi Salmaso. 2010. “Permutation Tests for Complex Data,” March. https://doi.org/10.1002/9780470689516.\n\n\n\n\n",
    "preview": "posts/2021-04-06-flipr-021/flipr-021_files/figure-html5/logo-1.png",
    "last_modified": "2022-02-01T14:34:31+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
